{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({6}, {4})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = [1, 2, 3, 4, 5]\n",
    "lst2 = [1, 2, 3, 5, 6]\n",
    "\n",
    "new_items = set(lst2) - set(lst1)\n",
    "removed_items = set(lst1) - set(lst2)\n",
    "new_items, removed_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1, 2: 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = {1:1, 2:2}\n",
    "d1.update({})\n",
    "d1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест одного видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131M/131M [00:11<00:00, 11.7MB/s] \n",
      "100%|██████████| 10/10 [00:06<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8x.pt')\n",
    "\n",
    "# Open the video file\n",
    "#video_path = r\"C:\\Users\\admin\\python_programming\\DATA\\AVABOS\\test_bboxes\\4LUoqxnyxlE(+)_._0.066-40.066.mp4\"\n",
    "video_path = r'I:\\AVABOS\\4LUoqxnyxlE(+)+ - test\\4LUoqxnyxlE(+).mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#results_log = []\n",
    "for i in tqdm(range(10)):\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True, verbose=False)\n",
    "    #results_log.append(results[0])\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ultralytics.models.yolo.detect.predict.DetectionPredictor at 0x5c2f11850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predictor#.trackers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_is_pytorch_model',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_hub_session',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_new',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_reset_ckpt_args',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_smart_load',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_callback',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'benchmark',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'callbacks',\n",
       " 'cfg',\n",
       " 'children',\n",
       " 'ckpt',\n",
       " 'ckpt_path',\n",
       " 'clear_callback',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embed',\n",
       " 'eval',\n",
       " 'export',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'fuse',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'info',\n",
       " 'ipu',\n",
       " 'is_hub_model',\n",
       " 'is_triton_model',\n",
       " 'load',\n",
       " 'load_state_dict',\n",
       " 'metrics',\n",
       " 'model',\n",
       " 'model_name',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'names',\n",
       " 'overrides',\n",
       " 'parameters',\n",
       " 'predict',\n",
       " 'predictor',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_callbacks',\n",
       " 'reset_weights',\n",
       " 'save',\n",
       " 'session',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'task',\n",
       " 'task_map',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'track',\n",
       " 'train',\n",
       " 'trainer',\n",
       " 'training',\n",
       " 'transforms',\n",
       " 'tune',\n",
       " 'type',\n",
       " 'val',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': 0,\n",
       " 'bicycle': 1,\n",
       " 'car': 2,\n",
       " 'motorcycle': 3,\n",
       " 'airplane': 4,\n",
       " 'bus': 5,\n",
       " 'train': 6,\n",
       " 'truck': 7,\n",
       " 'boat': 8,\n",
       " 'traffic light': 9,\n",
       " 'fire hydrant': 10,\n",
       " 'stop sign': 11,\n",
       " 'parking meter': 12,\n",
       " 'bench': 13,\n",
       " 'bird': 14,\n",
       " 'cat': 15,\n",
       " 'dog': 16,\n",
       " 'horse': 17,\n",
       " 'sheep': 18,\n",
       " 'cow': 19,\n",
       " 'elephant': 20,\n",
       " 'bear': 21,\n",
       " 'zebra': 22,\n",
       " 'giraffe': 23,\n",
       " 'backpack': 24,\n",
       " 'umbrella': 25,\n",
       " 'handbag': 26,\n",
       " 'tie': 27,\n",
       " 'suitcase': 28,\n",
       " 'frisbee': 29,\n",
       " 'skis': 30,\n",
       " 'snowboard': 31,\n",
       " 'sports ball': 32,\n",
       " 'kite': 33,\n",
       " 'baseball bat': 34,\n",
       " 'baseball glove': 35,\n",
       " 'skateboard': 36,\n",
       " 'surfboard': 37,\n",
       " 'tennis racket': 38,\n",
       " 'bottle': 39,\n",
       " 'wine glass': 40,\n",
       " 'cup': 41,\n",
       " 'fork': 42,\n",
       " 'knife': 43,\n",
       " 'spoon': 44,\n",
       " 'bowl': 45,\n",
       " 'banana': 46,\n",
       " 'apple': 47,\n",
       " 'sandwich': 48,\n",
       " 'orange': 49,\n",
       " 'broccoli': 50,\n",
       " 'carrot': 51,\n",
       " 'hot dog': 52,\n",
       " 'pizza': 53,\n",
       " 'donut': 54,\n",
       " 'cake': 55,\n",
       " 'chair': 56,\n",
       " 'couch': 57,\n",
       " 'potted plant': 58,\n",
       " 'bed': 59,\n",
       " 'dining table': 60,\n",
       " 'toilet': 61,\n",
       " 'tv': 62,\n",
       " 'laptop': 63,\n",
       " 'mouse': 64,\n",
       " 'remote': 65,\n",
       " 'keyboard': 66,\n",
       " 'cell phone': 67,\n",
       " 'microwave': 68,\n",
       " 'oven': 69,\n",
       " 'toaster': 70,\n",
       " 'sink': 71,\n",
       " 'refrigerator': 72,\n",
       " 'book': 73,\n",
       " 'clock': 74,\n",
       " 'vase': 75,\n",
       " 'scissors': 76,\n",
       " 'teddy bear': 77,\n",
       " 'hair drier': 78,\n",
       " 'toothbrush': 79}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2class_id = {val: key for key, val in model.names.items()}\n",
    "name2class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  152,  406,  699],\n",
       "       [ 615,  247,  999,  704],\n",
       "       [ 329,  184,  617,  705],\n",
       "       [ 948,  306, 1279,  711],\n",
       "       [ 153,  639,  257,  719],\n",
       "       [ 497,  107,  665,  480],\n",
       "       [ 987,  271, 1146,  599],\n",
       "       [ 647,  123,  778,  533],\n",
       "       [ 936,   92, 1122,  337],\n",
       "       [ 736,  126,  872,  442],\n",
       "       [ 124,  605,  218,  709],\n",
       "       [ 358,  558,  488,  704],\n",
       "       [ 880,  291, 1053,  523],\n",
       "       [  42,  680,  142,  719]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = results[0].boxes.xyxy.long().numpy()\n",
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].orig_img.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([640])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed(frame)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = results[0].boxes.xyxy.long().numpy()\n",
    "ids = results[0].boxes.id.long().numpy()\n",
    "target_classes_filter = results[0].boxes.cls==name2class_id['person']\n",
    "bboxes = bboxes[target_classes_filter]\n",
    "ids = ids[target_classes_filter]\n",
    "len(ids), len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 152, 406, 699)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0,y0,x1,y1 = bboxes[0]\n",
    "x0,y0,x1,y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_is_pytorch_model',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_hub_session',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_new',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_reset_ckpt_args',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_smart_load',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_callback',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'benchmark',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'callbacks',\n",
       " 'cfg',\n",
       " 'children',\n",
       " 'ckpt',\n",
       " 'ckpt_path',\n",
       " 'clear_callback',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embed',\n",
       " 'eval',\n",
       " 'export',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'fuse',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'info',\n",
       " 'ipu',\n",
       " 'is_hub_model',\n",
       " 'is_triton_model',\n",
       " 'load',\n",
       " 'load_state_dict',\n",
       " 'metrics',\n",
       " 'model',\n",
       " 'model_name',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'names',\n",
       " 'overrides',\n",
       " 'parameters',\n",
       " 'predict',\n",
       " 'predictor',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_callbacks',\n",
       " 'reset_weights',\n",
       " 'save',\n",
       " 'session',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'task',\n",
       " 'task_map',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'track',\n",
       " 'train',\n",
       " 'trainer',\n",
       " 'training',\n",
       " 'transforms',\n",
       " 'tune',\n",
       " 'type',\n",
       " 'val',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43., 47., 50., 51.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes_classes = results[0].boxes.cls\n",
    "bboxes_ids = results[0].boxes.id\n",
    "person_indices = bboxes_ids[bboxes_classes==0]\n",
    "person_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([43., 47., 50., 51.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes_ids[bboxes_classes==0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычисление распределения количества индексов, сгенерированных автоматическим трекером"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_id_num(path_to_vid):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/258 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23/258 [19:11<4:04:13, 62.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 25/258 [21:23<3:51:41, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 73/258 [1:11:25<1:07:36, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 103/258 [1:37:12<1:30:02, 34.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 155/258 [2:24:00<1:52:07, 65.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 157/258 [2:25:19<1:23:47, 49.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 191/258 [2:54:13<49:31, 44.35s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 223/258 [3:21:39<17:49, 30.56s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 240/258 [3:38:25<22:38, 75.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: not enough matching points\n",
      "WARNING: not enough matching points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [4:01:11<00:00, 56.09s/it] \n"
     ]
    }
   ],
   "source": [
    "paths_to_vids = glob.glob(r'I:\\AVABOS\\new_projects2\\*\\cut\\*.mp4')\n",
    "log_dict = {}\n",
    "for path_to_vid in tqdm(paths_to_vids):\n",
    "    model = YOLO('yolov8n.pt')\n",
    "    cap = cv2.VideoCapture(path_to_vid)\n",
    "    vid_name = os.path.split(path_to_vid)[-1]\n",
    "    results_log = []\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        results = model.track(frame, persist=True, verbose=False)\n",
    "        bboxes_classes = results[0].boxes.cls\n",
    "        bboxes_ids = results[0].boxes.id\n",
    "        try:\n",
    "            person_indices = bboxes_ids[bboxes_classes==0]\n",
    "            person_indices = person_indices.long().tolist()\n",
    "        except:\n",
    "            person_indices = []\n",
    "        results_log.append(person_indices)\n",
    "\n",
    "    log_dict[vid_name] = results_log\n",
    "    cap.release()\n",
    "\n",
    "with open('persons_ids_log.json', 'w', encoding='utf-8') as fd:\n",
    "    json.dump(log_dict, fd, indent=4)\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ количества рамок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_nums = []\n",
    "for vid_name, bboxes_list in log_dict.items():\n",
    "    unique_bboxes = []\n",
    "    for bboxes in bboxes_list:\n",
    "        unique_bboxes += bboxes\n",
    "\n",
    "    unique_bboxes = list(set(unique_bboxes))\n",
    "    print(f'Persons num in {vid_name}: {len(unique_bboxes)}')\n",
    "    bboxes_nums.append(len(unique_bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([        198,          35,          13,           3,           4,           0,           1,           1,           1,           2]),\n",
       " array([          0,          23,          46,          69,          92,         115,         138,         161,         184,         207,         230]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(bboxes_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 334,  185,  610,  699],\n",
       "       [   0,  153,  385,  700],\n",
       "       [ 499,  114,  660,  500],\n",
       "       [ 144,  635,  262,  718],\n",
       "       [ 129,  605,  220,  717],\n",
       "       [ 937,   93, 1118,  339],\n",
       "       [ 651,  246,  999,  699]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = results[0]\n",
    "boxes = res.boxes\n",
    "boxes.xyxy.numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861 (0.004)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.87155,     0.85545,     0.84388,     0.88015,     0.85851,       0.874,     0.87183,     0.83583,     0.86798,       0.855])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate a logistic regression model using repeated k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from scipy.stats import sem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = RepeatedKFold(n_splits=2, n_repeats=5, random_state=1)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='precision_macro', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), sem(scores)))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0.872,       0.856,       0.844,        0.88,       0.858,       0.874,       0.872,       0.836,       0.864,       0.854])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Черновики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "dataset = np.random.randn(1000, 256)\n",
    "\n",
    "#model = LDA()\n",
    "\n",
    "times_measure_list = []\n",
    "for X in dataset:\n",
    "    t0 = time.time()\n",
    "    res = model.predict(X)\n",
    "    t1 = time.time()\n",
    "    times_measure_list.append(t1-t0)\n",
    "\n",
    "np.mean(times_measure_list)\n",
    "stats.sem(times_measure_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316179"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "\n",
    "paths_to_all_videos = glob.glob(r'I:\\AVABOS\\new_projects2\\*\\cut\\*.mp4')\n",
    "\n",
    "frame_num_list = []\n",
    "for path in paths_to_all_videos:\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frame_num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    frame_num_list.append(frame_num)\n",
    "\n",
    "sum(frame_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5166666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lxml import etree\n",
    "import numpy as np\n",
    "\n",
    "path_to_eafs_list = glob.glob(r'i:\\AVABOS\\разбиение на интервалы со стабильным положением тел\\*\\*.eaf')\n",
    "\n",
    "persons_num_list = []\n",
    "for path in path_to_eafs_list:\n",
    "    tree = etree.parse(path)\n",
    "    tiers_list = tree.xpath('TIER[not(contains(@TIER_ID, \"НЕСТАБИЛЬНОЕ ВИДЕО\"))]')\n",
    "    persons_num_list.append(len(tiers_list))\n",
    "\n",
    "np.mean(persons_num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [3]\n",
    "lst.sort()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggr_rec",
   "language": "python",
   "name": "aggr_rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
